{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문제 (week5 input.txt)  \n",
    "출현하는 단어의 첫 번째 두 글자의 출현빈도를 세고 출현 빈도가 32보다 작은 (미만; <) 단어들의 출현빈도의 합은 이다  \n",
    "\n",
    "대소문자 구별하지 않음    \n",
    "첫 두 글자를 카운트하므로 길이가 2와 같거나 보다 긴 단어만 대상으로 함    \n",
    "공백은 당연 제외    \n",
    "문장부호(, . ? ‘ “ 등)은 따로 처리하지 않음   \n",
    "\n",
    "===> slicing을 통해 단어의 2개 글자만 뽑아내고, reduceByKey()하면 되는데 삽질....  \n",
    "===> 대소문자 구별하지 않음 의미파악 삽질....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext(\"local\", \"transformation 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatMap, filter이용 공백단어는 제거 \n",
    "readfile=sc.textFile(\"input.txt\").flatMap(lambda x: x.split(\" \")).filter(lambda x: x !=\"\")\n",
    "#readfile.collect()\n",
    "# ['A',\n",
    "#  'STUDY',\n",
    "#  'IN',\n",
    "#  'SCARLET.',\n",
    "#  'PART',\n",
    "#  'I.',\n",
    "#  '(Being',\n",
    "#  'a',,,,]\n",
    "\n",
    "#  첫글자에 공백있는 단어 있을 수 있는가?\n",
    "#  '“Looking',\n",
    "#  'for',\n",
    "#  'lodgings.”',\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어중 공백 있을 수 있어 제외  # 1문자인 것은 제외, 두 글자이상만 \n",
    "datas=readfile.map(lambda x: x.strip()).filter(lambda x: len(x)>=2)\n",
    "#datas.collect()\n",
    "# ['STUDY',\n",
    "#  'IN',\n",
    "#  'SCARLET.',\n",
    "#  'PART',\n",
    "#  'I.',\n",
    "#  '(Being',\n",
    "#  'reprint',\n",
    "#  'from',,,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 첫번째 두글자만 추출(slicing) 한 list 생성\n",
    "keys = datas.map(lambda x : x[:2])\n",
    "# ['ST',\n",
    "#  'IN',\n",
    "#  'SC',\n",
    "#  'PA',\n",
    "#  'I.',\n",
    "#  '(B',\n",
    "#  're',\n",
    "#  'fr',\n",
    "#  'th',,,,]\n",
    "# keys.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 대소문자구별하지 않으므로 소문자로 변경\n",
    "keys_lower = keys.map(lambda x: x.lower())\n",
    "# keys_lower.collect()\n",
    "# ['st',\n",
    "#  'in',\n",
    "#  'sc',\n",
    "#  'pa',\n",
    "#  'i.',\n",
    "#  '(b',\n",
    "#  're',\n",
    "#  'fr',\n",
    "#  'th',,,]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_tuple = keys_lower.map(lambda x:(x, 1))\n",
    "# keys_tuple.collect()\n",
    "# [('st', 1),\n",
    "#  ('in', 1),\n",
    "#  ('sc', 1),\n",
    "#  ('pa', 1),\n",
    "#  ('i.', 1),\n",
    "#  ('(b', 1),\n",
    "#  ('re', 1),\n",
    "#  ('fr', 1),,,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_tuple_reducebykey= keys_tuple.reduceByKey(lambda a,b : a+b)\n",
    "# keys_tuple_reducebykey.collect()\n",
    "# [('st', 515),\n",
    "#  ('in', 1076),\n",
    "#  ('sc', 70),\n",
    "#  ('pa', 188),\n",
    "#  ('i.', 9),\n",
    "#  ('(b', 1),\n",
    "#  ('re', 456),\n",
    "#  ('fr', 270),\n",
    "#  ('th', 4546),,,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filtered_32 = keys_tuple_reducebykey.filter(lambda v: v[1] < 32)\n",
    "# data_filtered_32.collect()\n",
    "# [('i.', 9),\n",
    "#  ('(b', 1),\n",
    "#  ('h.', 2),\n",
    "#  ('m.', 2),\n",
    "#  ('18', 2),\n",
    "#  ('gh', 7),\n",
    "#  ('“o', 19),\n",
    "#  ('ir', 14),\n",
    "#  ('ki', 19),;;]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "830"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data_filtered_32.values().collect()) # list\n",
    "sum (data_filtered_32.values().collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## python datatype으로 변경하여 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "0    st\n",
      "1    in\n",
      "2    sc\n",
      "3    pa\n",
      "4    i.\n",
      "dtype: object\n",
      "[4546 1689 1258 1256 1205 1135 1076 1006  937  888]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "830"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys_list = keys.map(lambda x:x).collect()\n",
    "keys_list = [ key.lower() for key in keys_list ]\n",
    "print(type(keys_list)) # list\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "ser = pd.Series(keys_list)\n",
    "print(ser.head())\n",
    "    # 0    ST\n",
    "    # 1    IN\n",
    "    # 2    SC\n",
    "    # 3    PA\n",
    "    # 4    I.\n",
    "    # dtype: object\n",
    "type(ser.value_counts().values) # <class 'list'>\n",
    "print(ser.value_counts().values[:10])\n",
    "    # [4167 1672 1248 1245 1105 1027 1012  968  921  809  745  624  540  527\n",
    "    #   507  487  477  472  455  441  440  422  408  394  385  371  366  363\n",
    "    #   361  338  333  321  319  313  309  293  293  2 ,,,]\n",
    "sum(list( filter(lambda x:x<32, ser.value_counts().values ) ))\n",
    "# 830"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'list'>\n",
      "830\n"
     ]
    }
   ],
   "source": [
    "datas_list=datas.map(lambda x:x).collect()\n",
    "datas_list= [ key.lower() for key in datas_list ]\n",
    "print(type(datas_list)) # list\n",
    "\n",
    "keys_list = keys.map(lambda x:x).collect()\n",
    "keys_list = [ key.lower() for key in keys_list ]\n",
    "print(type(keys_list)) # list\n",
    "\n",
    "# count위한 dict 생성\n",
    "kv_dict1 = dict(map(lambda x: (x,0), keys_list))\n",
    "\n",
    "for key, _ in kv_dict1.items():\n",
    "    for i in datas_list:\n",
    "#         print(f'{key}:{i}')\n",
    "#         tmp_list=[]\n",
    "        if key == i[0:2] : # str compare\n",
    "#             tmp_list.append(i)\n",
    "            kv_dict1[key] +=1 \n",
    "#         print(tmp_list)\n",
    "filtered_list1 = list( filter(lambda x: x <32, kv_dict1.values()) )\n",
    "print(sum(filtered_list1)) # 830"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'list'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "830"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datas_list=datas.map(lambda x:x).collect()\n",
    "datas_list= [ key.lower() for key in datas_list ]\n",
    "print(type(datas_list)) # list\n",
    "\n",
    "keys_list = keys.map(lambda x:x).collect()\n",
    "keys_list = [ key.lower() for key in keys_list ]\n",
    "print(type(keys_list)) # list\n",
    "\n",
    "# count위한 dict 생성\n",
    "kv_dict2 = dict(map(lambda x: (x,0), keys_list))\n",
    "\n",
    "# 알고리즘 \n",
    "for key, _ in kv_dict2.items():\n",
    "    for i in datas_list:\n",
    "#         print(f'{key}:{i}')\n",
    "#         tmp_list=[]\n",
    "        if key == i[0:2] : # str compare\n",
    "#             tmp_list.append(i)\n",
    "            kv_dict2[key] +=1 \n",
    "#         print(tmp_list)\n",
    "filtered_list2 = list( filter(lambda x: x <32, kv_dict2.values()) )\n",
    "sum(filtered_list2) # 830\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# data_tuple.foreach(lambda x: x[1] += 1 if x[0] in datas) # error\n",
    "# data_tuple.foreach(lambda x: x[1].mapValues(lambda v: v+1) if x[0] in datas )  # error\n",
    "# data_tuple.mapValues(lambda x: x[1]+=1 if x[0] in datas )  # error\n",
    "# data_tuple.foreach(lambda x: x[1].mapValues(lambda v: v+1) if x[0] in datas )  # error\n",
    "# datas.eachfor(lambda x: x.contains(data_list.map(lambda v:v)))  # error\n",
    "# data_=data_tuple.pipe(\"lambda x: x[1].mapValues(lambda v: v+1) if x[0] in datas\")\n",
    "# datas = datas.map(lambda x:(x,1))\n",
    "# datas.cogroup(data_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_tuple.filter(lambda x: x[0].contains(datas.map(lambda v:v)))\n",
    "# data_=data_tuple.filter(lambda x: x[0].contains(\"S\"))\n",
    "# data_=data_.mapValues(lambda x:x[1]+1)\n",
    "# data_.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# key, value에서 value에 의한 정렬\n",
    "# sortbyValue() 없음 # sortByKey()  #sortBy 있음\n",
    "data_sortby=data_reducebykey.sortBy(lambda a: a[1])\n",
    "#data_sortby.collect()\n",
    "# [('ST', 1),\n",
    "#  ('(B', 1),\n",
    "#  ('Gh', 1),\n",
    "#  ('Em', 1),\n",
    "#  ('“p', 1),\n",
    "#  ('Vo', 1),\n",
    "#  ('Bi', 1),,,,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapValue()\n",
    "# data_mapvalue = data_reducebykey.mapValues( lambda values: map(lambda v:filter(v)<=32 , values )) # Py4JJavaError\n",
    "# data_mapvalue = data_reducebykey.mapValues( lambda v: v+5 ) # ok\n",
    "\n",
    "data_mapvalue = data_reducebykey.mapValues(lambda v: v<=32 )  \n",
    "# [('ST', True),\n",
    "#  ('IN', True),\n",
    "#  ('SC', True),\n",
    "#  ('PA', True),\n",
    "#  ('I.', True),\n",
    "#  ('(B', True),\n",
    "#  ('re', False),\n",
    "#  ('fr', False),\n",
    "print(type(data_mapvlaue)) # pyspark.rdd.PipelinedRDD\n",
    "# data_mapvalue.collect()\n",
    "#data_mapvalue.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
